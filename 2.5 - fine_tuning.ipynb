{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure the transformer and torch modules are installed. I'm assuming that we're running under venv so it's ok to install modules. If this is not the case for you, install these whatever your custom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install transformers\n",
    "!{sys.executable} -m pip install torch\n",
    "!{sys.executable} -m pip install --upgrade jupyter\n",
    "!{sys.executable} -m pip install --upgrade ipywidgets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up the basic environment for a humbert model (https://huggingface.co/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM) and include some useful modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import json\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForMaskedLM\n",
    "\n",
    "# read my huggingface api token from a file into an environment variable\n",
    "with open('/Users/tjordan/code/secrets/huggingface', 'r') as file:\n",
    "    os.environ['HUGGINGFACE_API_TOKEN'] = file.read().replace('\\n', '')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve some text that we can use to play around with summarization (example is from Brazil Floods 2024 on reliefweb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "response = requests.get('https://api.reliefweb.int/v1/disasters/51859?appname=tom.jordan2@redcross.org')\n",
    "\n",
    "if response.status_code == 200:\n",
    "    response_data = response.json()\n",
    "else:\n",
    "    print('Error: ', response.status_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a peek and make sure we got what we thought\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Print the response\n",
    "\n",
    "pretty_response = json.dumps(response_data, indent=4)\n",
    "print(pretty_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the overview tag in the response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overview = response_data['data'][0]['fields']['profile']['overview']\n",
    "print(overview)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Explore some extraction models...NER (Named Entity Recognition) appears to be the thing we need to do to extract expected text (e.g. number killed, displaced, missing, etc) from an unstructured body of text. Common models for NER include "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
